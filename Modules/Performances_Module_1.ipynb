{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f716b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the weights \n",
    "def Weights_Save(i, model, file_name):\n",
    "    model.save_weights(file_name +str(i)+'.h5')\n",
    "    \n",
    "#load the weights \n",
    "def Weights_Load(i, model, file_name):\n",
    "    model.load_weights(file_name +str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db542d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "def Total_Performances(k, total_y_pred_train,total_y_true_train,total_y_pred_test,total_y_true_test):\n",
    "    total_cm_train=[]\n",
    "    total_cm_test=[]\n",
    "    total_accuracy_train=[]\n",
    "    total_accuracy_test=[]\n",
    "\n",
    "    total_sensitivity_train=[]\n",
    "    total_sensitivity_test=[]\n",
    "\n",
    "    total_specificity_train=[]\n",
    "    total_specificity_test=[]\n",
    "\n",
    "    total_MCC_train =[]\n",
    "    total_MCC_test =[]\n",
    "\n",
    "    total_AUC_train =[]\n",
    "    total_AUC_test =[]\n",
    "\n",
    "    for j in range(k):\n",
    "        y_pred_train = total_y_pred_train[j]\n",
    "        y_pred_test = total_y_pred_test[j] \n",
    "        y_true_train =total_y_true_train[j]\n",
    "        y_true_test = total_y_true_test[j]\n",
    "        \n",
    "        for i in range(len(y_pred_train)):\n",
    "            if y_pred_train[i] <0.5 :\n",
    "                y_pred_train[i] = 0\n",
    "            else :\n",
    "                y_pred_train[i] = 1\n",
    "    \n",
    "        for i in range(len(y_pred_test)):\n",
    "            if y_pred_test[i] <0.5:\n",
    "                y_pred_test[i] = 0\n",
    "            else :\n",
    "                y_pred_test[i] = 1   \n",
    "            \n",
    "        total_y_pred_train.append(y_pred_train)\n",
    "        total_y_pred_test.append(y_pred_test)\n",
    "    \n",
    "        total_cm_train.append(confusion_matrix(y_true_train, y_pred_train))\n",
    "        total_cm_test.append(confusion_matrix(y_true_test, y_pred_test))\n",
    "    \n",
    "    \n",
    "        total_MCC_train.append(matthews_corrcoef(y_true_train, y_pred_train))\n",
    "        total_MCC_test.append(matthews_corrcoef(y_true_test, y_pred_test))     \n",
    "        fpr1, tpr1, thresholds1 = roc_curve(y_true_train, y_pred_train, pos_label=1)\n",
    "        fpr2, tpr2, thresholds2 = roc_curve(y_true_test, y_pred_test, pos_label=1)\n",
    "        total_AUC_train.append(auc(fpr1, tpr1))\n",
    "        total_AUC_test.append(auc(fpr2,tpr2))\n",
    "        \n",
    "    for i in range(k):\n",
    "        c_m_train = total_cm_train[i]\n",
    "        c_m_test = total_cm_test[i]\n",
    "        total_cmtrain=sum(sum(c_m_train))\n",
    "        total_cmtest=sum(sum(c_m_test))\n",
    "    \n",
    "        trainAccuracy = (c_m_train[0,0]+c_m_train[1,1])/total_cmtrain\n",
    "        testAccuracy = (c_m_test[0,0]+c_m_test[1,1])/total_cmtest\n",
    "    \n",
    "        trainSensitivity = c_m_train[1,1]/(c_m_train[1,0]+c_m_train[1,1])\n",
    "        testSensitivity = c_m_test[1,1]/(c_m_test[1,0]+c_m_test[1,1])\n",
    "    \n",
    "        trainSpecificity = c_m_train[0,0]/(c_m_train[0,0]+c_m_train[0,1])\n",
    "        testSpecificity = c_m_test[0,0]/(c_m_test[0,0]+c_m_test[0,1])               \n",
    "    \n",
    "        total_accuracy_train.append(trainAccuracy)\n",
    "        total_accuracy_test.append(testAccuracy)\n",
    "        total_sensitivity_train.append(trainSensitivity)\n",
    "        total_sensitivity_test.append(testSensitivity)                      \n",
    "        total_specificity_train.append(trainSpecificity)\n",
    "        total_specificity_test.append(testSpecificity)\n",
    "        \n",
    "    for i in range (k): \n",
    "        total_accuracy_train[i]    =  round(total_accuracy_train[i],4)\n",
    "        total_accuracy_test[i]     =  round(total_accuracy_test[i],4)\n",
    "        total_sensitivity_train[i] =  round(total_sensitivity_train[i],4)\n",
    "        total_sensitivity_test[i]  =  round(total_sensitivity_test[i],4)\n",
    "        total_specificity_train[i] =  round(total_specificity_train[i],4)\n",
    "        total_specificity_test[i]  =  round(total_specificity_test[i],4)\n",
    "        total_MCC_train[i]         =  round(total_MCC_train[i],4)\n",
    "        total_MCC_test[i]          =  round(total_MCC_test[i],4)\n",
    "        total_AUC_train[i]         =  round(total_AUC_train[i],4)\n",
    "        total_AUC_test[i]          =  round(total_AUC_test[i],4)     \n",
    "        \n",
    "        total_performances_train = [total_accuracy_train,total_sensitivity_train,total_specificity_train, total_MCC_train,total_AUC_train]\n",
    "        total_performances_test = [total_accuracy_test,total_sensitivity_test,total_specificity_test, total_MCC_test,total_AUC_test]\n",
    "    return total_performances_train, total_performances_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277500f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Total_performances_ind_dataset(k,total_y_pred_test,total_y_true_test):\n",
    "    total_cm_test=[]\n",
    "    total_accuracy_test=[]  \n",
    "    total_sensitivity_test=[]\n",
    "    total_specificity_test=[]\n",
    "    total_MCC_test =[]\n",
    "    total_AUC_test =[]\n",
    "\n",
    "    for j in range(k):\n",
    "       \n",
    "        y_pred_test = total_y_pred_test[j] \n",
    "        y_true_test = total_y_true_test[j]\n",
    "    \n",
    "        for i in range(len(y_pred_test)):\n",
    "            if y_pred_test[i] <0.5:\n",
    "                y_pred_test[i] = 0\n",
    "            else :\n",
    "                y_pred_test[i] = 1   \n",
    "            \n",
    "        total_y_pred_test.append(y_pred_test)\n",
    "        total_cm_test.append(confusion_matrix(y_true_test, y_pred_test))\n",
    "    \n",
    "    \n",
    "        \n",
    "        total_MCC_test.append(matthews_corrcoef(y_true_test, y_pred_test))     \n",
    "        \n",
    "        fpr2, tpr2, thresholds2 = roc_curve(y_true_test, y_pred_test, pos_label=1)\n",
    "       \n",
    "        total_AUC_test.append(auc(fpr2,tpr2))\n",
    "        \n",
    "    for i in range(k):\n",
    "       \n",
    "        c_m_test = total_cm_test[i]\n",
    "       \n",
    "        total_cmtest=sum(sum(c_m_test))\n",
    "    \n",
    "       \n",
    "        testAccuracy = (c_m_test[0,0]+c_m_test[1,1])/total_cmtest\n",
    "    \n",
    "       \n",
    "        testSensitivity = c_m_test[1,1]/(c_m_test[1,0]+c_m_test[1,1])\n",
    "    \n",
    "       \n",
    "        testSpecificity = c_m_test[0,0]/(c_m_test[0,0]+c_m_test[0,1])               \n",
    "    \n",
    "       \n",
    "        total_accuracy_test.append(testAccuracy)\n",
    "        \n",
    "        total_sensitivity_test.append(testSensitivity)                      \n",
    "        \n",
    "        total_specificity_test.append(testSpecificity)\n",
    "        \n",
    "    for i in range (k): \n",
    "        \n",
    "        total_accuracy_test[i]     =  round(total_accuracy_test[i],4)\n",
    "       \n",
    "        total_sensitivity_test[i]  =  round(total_sensitivity_test[i],4)\n",
    "        \n",
    "        total_specificity_test[i]  =  round(total_specificity_test[i],4)\n",
    "        \n",
    "        total_MCC_test[i]          =  round(total_MCC_test[i],4)\n",
    "       \n",
    "        total_AUC_test[i]          =  round(total_AUC_test[i],4)     \n",
    "        \n",
    "        total_performances_test = [total_accuracy_test,total_sensitivity_test,total_specificity_test, total_MCC_test,total_AUC_test]\n",
    "    return total_performances_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a624a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
