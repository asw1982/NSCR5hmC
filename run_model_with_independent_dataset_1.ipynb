{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a56ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing package, object, and library\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ecf6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv file \n",
    "mat_x_f1 =[]\n",
    "mat_y_f1 =[]\n",
    "mat_x_f2 =[]\n",
    "mat_y_f2 =[]\n",
    "mat_x_f3 =[]\n",
    "mat_y_f3 =[]\n",
    "# there are 35 dataset to test my model \n",
    "for i in range(35):\n",
    "    \n",
    "    pd_ind_feature1 = pd.read_csv(\"CKSNAP/data_cksnap_\"+str(i)+ \".csv\")\n",
    "    pd_ind_feature2 = pd.read_csv(\"PseKNC/data_pseknc_\"+str(i)+ \".csv\")\n",
    "    pd_ind_feature3 = pd.read_csv(\"PSTNPss/data_pstnpss_\"+str(i)+ \".csv\") # the feature that give the best accuracy\n",
    "    \n",
    "    # get the label every feature\n",
    "    y_ind_feature1 = pd_ind_feature1[\"Target1\"] # y_feature1 = y_feature2 = y_feature3 \n",
    "    y_ind_feature2 = pd_ind_feature2[\"Target2\"]\n",
    "    y_ind_feature3 = pd_ind_feature3[\"Target3\"]\n",
    "    \n",
    "    mat_y_f1.append(y_ind_feature1)\n",
    "    mat_y_f2.append(y_ind_feature2)\n",
    "    mat_y_f3.append(y_ind_feature3)\n",
    "# delete column target\n",
    "    del pd_ind_feature1[\"Target1\"]\n",
    "    del pd_ind_feature2[\"Target2\"]\n",
    "    del pd_ind_feature3[\"Target3\"]\n",
    "\n",
    "    x_feature1 = pd_ind_feature1\n",
    "    x_feature2 = pd_ind_feature2\n",
    "    x_feature3 = pd_ind_feature3\n",
    "    \n",
    "    mat_x_f1.append(x_feature1)\n",
    "    mat_x_f2.append(x_feature2)\n",
    "    mat_x_f3.append(x_feature3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aac255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the features \n",
    "#%run ./best_featureRNA.ipynb \n",
    "# merge the feature\n",
    "# 1. CKSNAP(1) and PseKNC(2)\n",
    "# 2. CKSNAP and PSTNPss(3)\n",
    "# 3. PseKNC and PSTNPss\n",
    "# 4. CKSNAP and PseKNC and PSTNPss\n",
    "nCV = 10\n",
    "\n",
    "# don't use numpy array\n",
    "mat_x_merge1 =[]\n",
    "mat_x_merge2 =[]\n",
    "mat_x_merge3 =[]\n",
    "mat_x_merge4 =[]\n",
    "\n",
    "for i in range(35):\n",
    "    X1 = mat_x_f1[i]\n",
    "    X2 = mat_x_f2[i]\n",
    "    X3 = mat_x_f3[i]\n",
    "\n",
    "    X_merge1 = pd.concat([X1,X2], axis=1) # 1. CKSNAP and PseKNC\n",
    "    X_merge2 = pd.concat([X1,X3], axis=1) # 2. CKSNAP and PSTNPss(3)\n",
    "    X_merge3 = pd.concat([X2,X3], axis=1) # 3. PseKNC and PSTNPss\n",
    "    X_merge4 = pd.concat([X1,X2,X3], axis=1) # 4. CKSNAP and PseKNC and PSTNPss\n",
    "    mat_x_merge1.append(np.array(X_merge1,dtype=\"float64\"))\n",
    "    mat_x_merge2.append(np.array(X_merge2,dtype=\"float64\"))\n",
    "    mat_x_merge3.append(np.array(X_merge3,dtype=\"float64\"))\n",
    "    mat_x_merge4.append(np.array(X_merge4,dtype=\"float64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000c7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of bad feature\n",
    "from numpy import load \n",
    "list_bad_feature1= load('list_bad_feature1.npy') \n",
    "list_bad_feature2= load('list_bad_feature2.npy') \n",
    "list_bad_feature3= load('list_bad_feature3.npy') \n",
    "list_bad_feature4= load('list_bad_feature4.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2ae9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "80\n",
      "85\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "print(len(list_bad_feature1))\n",
    "print(len(list_bad_feature2))\n",
    "print(len(list_bad_feature3))\n",
    "print(len(list_bad_feature4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69528746",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_reduced_f1=[]\n",
    "mat_reduced_f2=[]\n",
    "mat_reduced_f3=[]\n",
    "mat_reduced_f4=[]\n",
    "\n",
    "for i in range(35):\n",
    "    mat_reduced_f1.append(np.delete(mat_x_merge1[i], list_bad_feature1, axis=1)) \n",
    "    mat_reduced_f2.append(np.delete(mat_x_merge2[i], list_bad_feature2, axis=1)) \n",
    "    mat_reduced_f3.append(np.delete(mat_x_merge3[i], list_bad_feature3, axis=1)) \n",
    "    mat_reduced_f4.append(np.delete(mat_x_merge4[i], list_bad_feature4, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2615b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1738, 21)\n",
      "(1738, 23)\n",
      "(1738, 20)\n",
      "(1738, 31)\n"
     ]
    }
   ],
   "source": [
    "print(mat_reduced_f1[0].shape)\n",
    "print(mat_reduced_f2[0].shape)\n",
    "print(mat_reduced_f3[0].shape)\n",
    "print(mat_reduced_f4[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36271bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= mat_y_f1[0]\n",
    "y=np.array(y)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9dce624",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.5000000e-02,  2.5000000e-02,  5.0000000e-02, ...,\n",
       "        -4.6401130e-03,  4.5685230e-03,  1.0342149e-02],\n",
       "       [ 2.5000000e-02,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         6.8925560e-03, -5.7736260e-03,  1.0340823e-02],\n",
       "       [ 1.5000000e-01,  1.0000000e-01,  7.5000000e-02, ...,\n",
       "         9.2020070e-03,  2.2895640e-03, -1.9900000e-05],\n",
       "       ...,\n",
       "       [ 5.0000000e-02,  2.5000000e-02,  5.0000000e-02, ...,\n",
       "         8.0737960e-03, -1.6106495e-02, -6.8832760e-03],\n",
       "       [ 0.0000000e+00,  2.5000000e-02,  7.5000000e-02, ...,\n",
       "        -1.1361650e-03,  3.1800000e-05,  1.1746110e-03],\n",
       "       [ 5.0000000e-02,  2.5000000e-02,  2.5000000e-02, ...,\n",
       "         1.1679830e-03,  1.1772630e-03,  1.1746110e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_reduced_f2[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d9584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset number :0 have score :0.5281933256616801\n",
      "dataset number :1 have score :0.45972382048331417\n",
      "dataset number :2 have score :0.4096662830840046\n",
      "dataset number :3 have score :0.46777905638665135\n",
      "dataset number :4 have score :0.5828538550057537\n",
      "dataset number :5 have score :0.501150747986191\n",
      "dataset number :6 have score :0.520138089758343\n",
      "dataset number :7 have score :0.5069044879171462\n",
      "dataset number :8 have score :0.503452243958573\n",
      "dataset number :9 have score :0.5454545454545454\n",
      "dataset number :10 have score :0.503452243958573\n",
      "dataset number :11 have score :0.5926352128883774\n",
      "dataset number :12 have score :0.57307249712313\n",
      "dataset number :13 have score :0.5161104718066744\n",
      "dataset number :14 have score :0.5028768699654775\n",
      "dataset number :15 have score :0.5840046029919448\n",
      "dataset number :16 have score :0.5477560414269275\n",
      "dataset number :17 have score :0.5327963176064442\n",
      "dataset number :18 have score :0.5069044879171462\n",
      "dataset number :19 have score :0.5120828538550057\n",
      "dataset number :20 have score :0.5788262370540852\n",
      "dataset number :21 have score :0.4936708860759494\n",
      "dataset number :22 have score :0.546029919447641\n",
      "dataset number :23 have score :0.6219792865362486\n",
      "dataset number :24 have score :0.5069044879171462\n",
      "dataset number :25 have score :0.5281933256616801\n",
      "dataset number :26 have score :0.5155350978135789\n",
      "dataset number :27 have score :0.5172612197928653\n",
      "dataset number :28 have score :0.520138089758343\n",
      "dataset number :29 have score :0.5051783659378596\n",
      "dataset number :30 have score :0.5788262370540852\n",
      "dataset number :31 have score :0.5368239355581128\n",
      "dataset number :32 have score :0.5207134637514385\n",
      "dataset number :33 have score :0.5155350978135789\n",
      "dataset number :34 have score :0.5759493670886076\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.load('Stacked_model/Stacked3_fold9.joblib')\n",
    "for i in range(35):\n",
    "    result = loaded_model.score(mat_reduced_f3[i], y)\n",
    "    print(f'dataset number :{i} have score :{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84600588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fold number 0 scores 0.6294591484464902\n",
      " fold number 1 scores 0.6052934407364787\n",
      " fold number 2 scores 0.5828538550057537\n",
      " fold number 3 scores 0.5736478711162255\n",
      " fold number 4 scores 0.6237054085155351\n",
      " fold number 5 scores 0.6012658227848101\n",
      " fold number 6 scores 0.6121979286536249\n",
      " fold number 7 scores 0.6283084004602992\n",
      " fold number 8 scores 0.6352128883774454\n",
      " fold number 9 scores 0.5840046029919448\n"
     ]
    }
   ],
   "source": [
    "# based on experiments, dataset number 15 is the best in accuracy score\n",
    "# check the score in every fold \n",
    "total_y_pred_test =[]\n",
    "total_y_true_test=[]\n",
    "for i in range(10): # i use 10 fold so, i have 10 models\n",
    "    loaded_model = joblib.load('Stacked_model/Stacked3_fold'+str(i)+'.joblib')\n",
    "    result = loaded_model.score(mat_reduced_f3[15], y)\n",
    "    y_pred_test = loaded_model.predict(mat_reduced_f3[15])\n",
    "    total_y_pred_test.append(y_pred_test)\n",
    "    total_y_true_test.append(y)\n",
    "  \n",
    "    print(f' fold number {i} scores {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c57c20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, roc_curve, auc \n",
    "def Total_performances_ind_dataset(k,total_y_pred_test,total_y_true_test):\n",
    "    total_cm_test=[]\n",
    "    total_accuracy_test=[]  \n",
    "    total_sensitivity_test=[]\n",
    "    total_specificity_test=[]\n",
    "    total_MCC_test =[]\n",
    "    total_AUC_test =[]\n",
    "\n",
    "    for j in range(k):\n",
    "       \n",
    "        y_pred_test = total_y_pred_test[j] \n",
    "        y_true_test = total_y_true_test[j]\n",
    "    \n",
    "        for i in range(len(y_pred_test)):\n",
    "            if y_pred_test[i] <0.5:\n",
    "                y_pred_test[i] = 0\n",
    "            else :\n",
    "                y_pred_test[i] = 1   \n",
    "            \n",
    "        total_y_pred_test.append(y_pred_test)\n",
    "        total_cm_test.append(confusion_matrix(y_true_test, y_pred_test))\n",
    "    \n",
    "    \n",
    "        \n",
    "        total_MCC_test.append(matthews_corrcoef(y_true_test, y_pred_test))     \n",
    "        \n",
    "        fpr2, tpr2, thresholds2 = roc_curve(y_true_test, y_pred_test, pos_label=1)\n",
    "       \n",
    "        total_AUC_test.append(auc(fpr2,tpr2))\n",
    "        \n",
    "    for i in range(k):\n",
    "       \n",
    "        c_m_test = total_cm_test[i]\n",
    "       \n",
    "        total_cmtest=sum(sum(c_m_test))\n",
    "    \n",
    "       \n",
    "        testAccuracy = (c_m_test[0,0]+c_m_test[1,1])/total_cmtest\n",
    "    \n",
    "       \n",
    "        testSensitivity = c_m_test[1,1]/(c_m_test[1,0]+c_m_test[1,1])\n",
    "    \n",
    "       \n",
    "        testSpecificity = c_m_test[0,0]/(c_m_test[0,0]+c_m_test[0,1])               \n",
    "    \n",
    "       \n",
    "        total_accuracy_test.append(testAccuracy)\n",
    "        \n",
    "        total_sensitivity_test.append(testSensitivity)                      \n",
    "        \n",
    "        total_specificity_test.append(testSpecificity)\n",
    "        \n",
    "    for i in range (k): \n",
    "        \n",
    "        total_accuracy_test[i]     =  round(total_accuracy_test[i],4)\n",
    "       \n",
    "        total_sensitivity_test[i]  =  round(total_sensitivity_test[i],4)\n",
    "        \n",
    "        total_specificity_test[i]  =  round(total_specificity_test[i],4)\n",
    "        \n",
    "        total_MCC_test[i]          =  round(total_MCC_test[i],4)\n",
    "       \n",
    "        total_AUC_test[i]          =  round(total_AUC_test[i],4)     \n",
    "        \n",
    "        total_performances_test = [total_accuracy_test,total_sensitivity_test,total_specificity_test, total_MCC_test,total_AUC_test]\n",
    "    return total_performances_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e77f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_performances_test = Total_performances_ind_dataset(10,total_y_pred_test,total_y_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9de98500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.6075999999999999\n",
      "sn : 0.63568\n",
      "sp : 0.57953\n",
      "mcc : 0.21589\n",
      "auc : 0.6075999999999999\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "acc_mean = statistics.mean(total_performances_test[0])\n",
    "sn_mean =statistics.mean(total_performances_test[1])\n",
    "sp_mean =statistics.mean(total_performances_test[2])\n",
    "mcc_mean =statistics.mean(total_performances_test[3])\n",
    "auc_mean=statistics.mean(total_performances_test[4])\n",
    "\n",
    "print(f'acc : {acc_mean}')\n",
    "print(f'sn : {sn_mean}')\n",
    "print(f'sp : {sp_mean}')\n",
    "print(f'mcc : {mcc_mean}')\n",
    "print(f'auc : {auc_mean}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c998e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
